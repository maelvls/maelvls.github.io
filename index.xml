<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>maelvls dev blog</title><link>https://maelvls.dev/</link><description>Recent content on maelvls dev blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 22 Mar 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://maelvls.dev/index.xml" rel="self" type="application/rss+xml"/><item><title>Migrating from GKE to Civo's K3s</title><link>https://maelvls.dev/from-gke-to-civo-k3s/</link><pubDate>Sun, 22 Mar 2020 00:00:00 +0000</pubDate><guid>https://maelvls.dev/from-gke-to-civo-k3s/</guid><description>A few days ago, reality hit me hard with this message:
I had only 2 days to find a plan and migrate everything away from GKE! My current setup was only using a single n1-standard-1 on us-west-1 and with no network load balancer. But that was still around â‚¬15 a month and I just didn&amp;rsquo;t want to pay.
Note that I will still use Google&amp;rsquo;s CloudDNS service for now.
I chose to migrate to Civo&amp;rsquo;s managed K3s since they are in beta and I really wanted to try K3s.</description></item><item><title>The Packet's-Eye View of a Kubernetes Service</title><link>https://maelvls.dev/packets-eye-kubernetes-service/</link><pubDate>Sat, 14 Mar 2020 00:00:00 +0000</pubDate><guid>https://maelvls.dev/packets-eye-kubernetes-service/</guid><description>2. how service and ingress interact with their controllers 3. traffic flow with GKE's service LB and Traefik 4. using my own service controller 5. traffic flow with my own service controller 6. comparison, benchmark, recap -- A few weeks back, I had already written about how to avoid the expensive GKE load balancer. This time, I want to go a bit deeper and detail how the Service object routes packets to a pod and how the &amp;lsquo;hostPort&amp;rsquo; method actually works under the hood.</description></item><item><title>You should write comments</title><link>https://maelvls.dev/you-should-write-comments/</link><pubDate>Thu, 27 Feb 2020 00:00:00 +0000</pubDate><guid>https://maelvls.dev/you-should-write-comments/</guid><description>Comments is one of these topics that we seem to never agree on (stackoverflow says so). I often hear that comments add noise to the code and that comments never get properly updated.
The solution seems to be to properly self-document code. And I love Go for that; one of the Go proverbs even says:
Clear is better than clever.
It is true that Go favors easy-to-read code rather than smart-but-hard-to-parse code, which really helps keeping the level of comments low.</description></item><item><title>Debugging Kubernetes Networking: my kube-dns is not working!</title><link>https://maelvls.dev/debugging-kubernetes-networking/</link><pubDate>Sun, 26 Jan 2020 00:00:00 +0000</pubDate><guid>https://maelvls.dev/debugging-kubernetes-networking/</guid><description>When I scaled my GKE cluster from one node to two nodes, I realised there was some DNS issues with one of the pods on the new Node 2 (that&amp;rsquo;s what I initially thought).
So I went into pod-on-2 (10.24.12.40) and checked that DNS wasn&amp;rsquo;t working. What I did is run
% gcloud compute ssh node-2 % docker run --rm -it --net=container:$(docker ps | grep POD_pod-on-2 | head -1 | cut -f1 -d&amp;#34; &amp;#34;) nicolaka/netshoot % nslookup github.</description></item><item><title>Avoid GKE's expensive load balancer by using hostPort</title><link>https://maelvls.dev/avoid-gke-lb-with-hostport/</link><pubDate>Mon, 20 Jan 2020 00:00:00 +0000</pubDate><guid>https://maelvls.dev/avoid-gke-lb-with-hostport/</guid><description>I like being able to keep my own GKE Kubernetes cluster for experimenting. But I realized that this Network Load Balancer was way too expensive.
What happens is that GKE has a LoadBalancer controller running (I can&amp;rsquo;t see it) and whenever I have a service with type: LoadBalancer, it will create a L4 load balancer that balances 80 and 443 traffic across the nodes. Here is a diagram of my current setup:</description></item><item><title>What to do when Go ignores HTTP_PROXY for 127.0.0.1</title><link>https://maelvls.dev/go-ignores-proxy-localhost/</link><pubDate>Mon, 06 Jan 2020 00:00:00 +0000</pubDate><guid>https://maelvls.dev/go-ignores-proxy-localhost/</guid><description>I use Proxyman for inspecting the HTTP and HTTPS traffic coming from applications. For example, you may want to know which API calls are made by docker when running docker search. What I would do is
HTTPS_PROXY=http://localhost:9090 docker search ubuntu Since Proxyman acts like a proxy listening on 0.0.0.0:9090, I can see and replay all the HTTP calls, similarly to what you would do with the Chrome DevTools.
Note that HTTPS is a bit tricky and requires an additional step on macOS (settings &amp;gt; Proxyman CA &amp;gt; Generate new) but works flawlessly with any Go binary since Go supports HTTPS_PROXY by default.</description></item><item><title>Go Happy Path: the Unindented Line of Sight</title><link>https://maelvls.dev/go-happy-line-of-sight/</link><pubDate>Sat, 23 Nov 2019 00:00:00 +0000</pubDate><guid>https://maelvls.dev/go-happy-line-of-sight/</guid><description>While perusing how other Kubernetes developers are implementing their own reconciliation loop, I came across an interesting piece of code.
The author decided to use the if-else control flow at its maximum potential: the logic goes as deep as three tabs to the right. We cannot immediately guess which parts are important and which aren&amp;rsquo;t.
func (r *ReconcileTrial) reconcileJob(instance *trialsv1alpha3.Trial, desiredJob *unstructured.Unstructured) (*unstructured.Unstructured, error) { var err error logger := log.</description></item><item><title>GO111MODULE is everywhere: history and tips</title><link>https://maelvls.dev/go111module-everywhere/</link><pubDate>Wed, 13 Nov 2019 00:00:00 +0000</pubDate><guid>https://maelvls.dev/go111module-everywhere/</guid><description>You might have noticed that GO111MODULE=on is flourishing everywhere. Many readmes have that:
GO111MODULE=on go get -u golang.org/x/tools/gopls@latest In this short post, I will explain why GO111MODULE exists, its caveats and interesting bits that you need to know when dealing with Go Modules.
Table of contents:
From GOPATH to GO111MODULE The GO111MODULE environment variable GO111MODULE with Go 1.11 and 1.12 GO111MODULE with Go 1.13 So, why is GO111MODULE everywhere?</description></item><item><title>Use of conditions in Kubernetes controllers</title><link>https://maelvls.dev/kubernetes-conditions/</link><pubDate>Tue, 12 Nov 2019 00:00:00 +0000</pubDate><guid>https://maelvls.dev/kubernetes-conditions/</guid><description>While building a Kubernetes controller using CRDs, I stumbled across &amp;lsquo;conditions&amp;rsquo; in the status field. What are conditions and how should I implement them in my controller?
In this post, I will explain what &amp;lsquo;status conditions&amp;rsquo; are in Kubernetes and show how they can be used in your own controllers.
Table of contents:
Pod example What other projects do Conditions vs. State machine Conditions vs. Events Orthogonality vs. Extensibility Are Conditions still used?</description></item><item><title>About</title><link>https://maelvls.dev/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://maelvls.dev/about/</guid><description>I currently work at Ori, a cloud infrastructure startup that aims at providing a unified experience for deploying to close-to-the-user compute resources.
I mostly write Go, Kubernetes controllers and network-related components.
I completed a PhD in logic in 2019 (papers).</description></item></channel></rss>