<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>networking on maelvls dev blog</title>
    <link>https://maelvls.dev/do-not-share-yet/tags/networking/</link>
    <description>Recent content in networking on maelvls.dev</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 25 Jul 2020 00:00:00 +0000</lastBuildDate>
    
    <atom:link href="https://maelvls.dev/do-not-share-yet/tags/networking/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>It&#39;s always the DNS&#39; fault</title>
      <link>https://maelvls.dev/do-not-share-yet/notes/dns/</link>
      <pubDate>Sat, 25 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://maelvls.dev/do-not-share-yet/notes/dns/</guid>
      <description>
      
      Terms A domain name (or just “domain”) is a string the form bar.foo.com.. Not all domains refer to physical ...
      
      </description>
    </item>
    <item>
      <title>Expose Service Using Kind on Macos</title>
      <link>https://maelvls.dev/do-not-share-yet/expose-service-using-kind-on-macos/</link>
      <pubDate>Tue, 21 Jul 2020 10:07:11 +0200</pubDate>
      
      <guid>https://maelvls.dev/do-not-share-yet/expose-service-using-kind-on-macos/</guid>
      <description>
      
      
      
      </description>
    </item>
    <item>
      <title>Pull-through Docker registry on Kind clusters</title>
      <link>https://maelvls.dev/do-not-share-yet/docker-proxy-registry-kind/</link>
      <pubDate>Fri, 03 Jul 2020 15:13:39 +0200</pubDate>
      
      <guid>https://maelvls.dev/do-not-share-yet/docker-proxy-registry-kind/</guid>
      <description>
      
      Kind offers an excellent UX to Kubernetes developers but lacks support for caching images; each time you recreate a new cluster, all the previous downloaded images are gone. In this post, I explain why the default Docker network is a trap and how to set up a registry &amp; make sure that it actually works.
      
      </description>
    </item>
    <item>
      <title>Using mitmproxy to understand what kubectl does under the hood</title>
      <link>https://maelvls.dev/do-not-share-yet/mitmproxy-kubectl/</link>
      <pubDate>Wed, 01 Jul 2020 19:17:24 +0200</pubDate>
      
      <guid>https://maelvls.dev/do-not-share-yet/mitmproxy-kubectl/</guid>
      <description>
      
      Mitmproxy is an excellent tool that helps us understand what network calls are made by programs. And kubectl is one of these interesting programs, but it uses a mutual TLS authentication which is tricky to get right.
      
      </description>
    </item>
    <item>
      <title>How do packets find their way back?</title>
      <link>https://maelvls.dev/do-not-share-yet/how-do-packets-come-back/</link>
      <pubDate>Mon, 13 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://maelvls.dev/do-not-share-yet/how-do-packets-come-back/</guid>
      <description>
      
      In one of my previous posts, I studied how traffic flows when using
Kubernetes Services. While drawing the last diagram, I did not clearly
see how traffic could make its way back to the user. In this
post, I focus on how packets find their way back and what makes stateless
rewriting interesting.

      
      </description>
    </item>
    <item>
      <title>The Packet&#39;s-Eye View of a Kubernetes Service</title>
      <link>https://maelvls.dev/do-not-share-yet/packets-eye-kubernetes-service/</link>
      <pubDate>Sat, 14 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://maelvls.dev/do-not-share-yet/packets-eye-kubernetes-service/</guid>
      <description>
      
      The Service and Ingress respectively brings L4 and L7 traffics to your
pods. In this article, I focus on how traffic flows in and what are the
interactions between the ingress controller and the &#34;service-lb controller&#34;
(the thing that creates the external load balancer). I also detail how the
`hostPort` approach shapes traffic.

      
      </description>
    </item>
    <item>
      <title>Debugging Kubernetes Networking: my kube-dns is not working!</title>
      <link>https://maelvls.dev/do-not-share-yet/debugging-kubernetes-networking/</link>
      <pubDate>Sun, 26 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://maelvls.dev/do-not-share-yet/debugging-kubernetes-networking/</guid>
      <description>
      
      Some pods were unable to connect to the kube-proxy pod on one of my GKE
Kubernetes clusters. This post present an in-depth investigation using
tcpdump, wireshark and iptables tracing.

      
      </description>
    </item>
    <item>
      <title>Avoid GKE&#39;s expensive load balancer by using hostPort</title>
      <link>https://maelvls.dev/do-not-share-yet/avoid-gke-lb-with-hostport/</link>
      <pubDate>Mon, 20 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://maelvls.dev/do-not-share-yet/avoid-gke-lb-with-hostport/</guid>
      <description>
      
      I want to avoid using the expensive Google Network Load Balancer and
instead do the load balancing in-cluster using akrobateo, which
acts as a LoadBalancer controller.

      
      </description>
    </item>
    
  </channel>
</rss>
