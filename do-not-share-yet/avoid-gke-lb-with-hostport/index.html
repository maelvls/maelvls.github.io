<!DOCTYPE html>
<html lang="en"><head>

  <meta name="generator" content="Hugo 0.64.0" />
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="author" content="Ma√´l Valais"><meta name="keywords" content="kubernetes,networking"><meta name="description" content="I want to avoid using the expensive Google Network Load Balancer and
instead do the load balancing in-cluster using akrobateo, which
acts as a LoadBalancer controller.
"><meta property="og:title" content="Avoid GKE&#39;s expensive load balancer by using hostPort" />
<meta property="og:description" content="I want to avoid using the expensive Google Network Load Balancer and
instead do the load balancing in-cluster using akrobateo, which
acts as a LoadBalancer controller.
" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://maelvls.dev/do-not-share-yet/avoid-gke-lb-with-hostport/" />
<meta property="og:image" content="https://maelvls.dev/do-not-share-yet/avoid-gke-lb-with-hostport/cover-external-dns.png" />
<meta property="article:published_time" content="2020-01-20T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-01-20T00:00:00+00:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://maelvls.dev/do-not-share-yet/avoid-gke-lb-with-hostport/cover-external-dns.png"/>

<meta name="twitter:title" content="Avoid GKE&#39;s expensive load balancer by using hostPort"/>
<meta name="twitter:description" content="I want to avoid using the expensive Google Network Load Balancer and
instead do the load balancing in-cluster using akrobateo, which
acts as a LoadBalancer controller.
"/>
<link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
  <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
  <link rel="stylesheet" type="text/css" media="screen" href="https://maelvls.dev/do-not-share-yet/css/normalize.css" />
  <link rel="stylesheet" type="text/css" media="screen" href="https://maelvls.dev/do-not-share-yet/css/main.css" />
  <link rel="stylesheet" type="text/css" media="screen" href="https://maelvls.dev/do-not-share-yet/css/all.css" />
<link rel="stylesheet" type="text/css" media="screen" href="https://maelvls.dev/do-not-share-yet/css/maelvls.css" /><title>Avoid GKE&#39;s expensive load balancer by using hostPort | maelvls dev blog</title></head>
<body>

<header>

  <div id="avatar">
    <a href="https://maelvls.dev/do-not-share-yet/">
      <img src="/img/mael.jpg" alt="maelvls dev blog">
    </a>
  </div>

  <div id="titletext"><h2 id="title"><a href="https://maelvls.dev/do-not-share-yet/">maelvls dev blog</a></h2></div>
  <div id="title-description"><p id="subtitle">Systems software engineer. I write mostly about Kubernetes and Go. <a href="/about">About</a></p><div id=social>
    <nav>
      <ul><li><a href="https://github.com/maelvls"><i title="Github" class="icons fab fa-github"></i></a></li><li><a href="https://twitter.com/maelvls"><i title="Twitter" class="icons fab fa-twitter"></i></a></li></ul>
    </nav>
  </div>
  </div>
  <div id="mainmenu">
	
  </div>
</header>
<main><div class="post">
<div class="author">

</div>
<div class="post-header">

<div class="meta">
<div class="date">
<span class="day">20</span>
<span class="rest">Jan 2020</span>
</div>
</div>

<div class="matter">
<h1 class="title">Avoid GKE&#39;s expensive load balancer by using hostPort</h1>
</div>
</div>
<div class="markdown">
<blockquote>
<p><strong>‚ö†Ô∏è Update 25 April 2020</strong>: Akrobateo has been EOL in January 2020 due
to the company going out of business. Their blog post regarding the EOL
isn&rsquo;t available anymore and was probably shut down. Fortunately, the
Wayback Machine <a href="https://web.archive.org/web/20200107111252/https://blog.kontena.io/farewell/">has a snapshot of the
post</a>
(7th January 2020). Here is an excerpt:</p>
<blockquote>
<p>This is a sad day for team Kontena. We tried to build something amazing
but our plans of creating business around open source software has
failed. We couldn&rsquo;t build a sustainable business. Despite all the
effort, highs and lows, as of today, Kontena has ceased operations. The
team is no more and the official support for Kontena products is no
more available.</p>
</blockquote>
<p>This is so sad&hellip; üò¢ Note that the Github repo
<a href="https://github.com/kontena/akrobateo">kontena/akrobateo</a> is still there
(and has not been archived yet), but their Docker registry has been shut
down which means most of this post is broken.</p>
</blockquote>
<p>In my spare time, I maintain a tiny &ldquo;playground&rdquo; Kubernetes cluster on
<a href="https://cloud.google.com/kubernetes-engine">GKE</a> (helm charts
<a href="https://github.com/maelvls/k.maelvls.dev">here</a>). I quickly realized that
realized using <code>Service type=LoadBalancer</code> in GKE was spawning a <em><a href="https://cloud.google.com/load-balancing/docs/network">Network
Load Balancer</a></em> which
costs approximately <strong>$15 per month</strong>! In this post, I present a way of
avoiding the expensive Google Network Load Balancer by load balancing
in-cluster using akrobateo, which acts as a Service type=LoadBalancer
controller.</p>
<blockquote>
<p>‚úÖ Since this method uses the worker node&rsquo;s external IPs, we can&rsquo;t really
say it is a real &ldquo;load balancing&rdquo; mechanism (i.e., this method doesn&rsquo;t
handle IP failover and doesn&rsquo;t even tolerate node failures). But in my
tiny setup, it makes a lot of sense to use that.</p>
</blockquote>
<p><img src="cost-load-balancer-gke.png" alt="Network Load Balancing: Forwarding Rule Minimum Service Charge in EMEA"></p>
<p>What happens is that GKE has a LoadBalancer controller running (I can&rsquo;t see
it) and whenever I have a service with <code>type: LoadBalancer</code>, it will create
a L4 load balancer that balances 80 and 443 traffic across the nodes. Here
is a diagram of my current setup:</p>
<p><img src="how-service-controller-works-on-gke.png" alt="ExternalDNS, GKE and Traefik"></p>
<p>I use Traefik as a reverse-proxy and terminates the end-user TLS
connection. And since Traefik sets the <code>status.loadBalancer.ingress</code> on the
ingress objects, I can also use
<a href="https://github.com/kubernetes-sigs/external-dns/">ExternalDNS</a> for setting
the <code>A</code> records automatically (I use Cloud DNS).</p>
<p>What if I stopped using the LoadBalancer service and use a <code>NodePort</code> instead? Two reasons against that:</p>
<ol>
<li>GKE <a href="https://issues.k8s.io/9995">restricts</a> the ports you can use to
30000 and above. So I would end up with <code>https://kube.maelvls.dev:30145</code>
and I definitely don&rsquo;t want that. I want to use 80 and 443.</li>
<li>Traefik uses the LoadBalancer service&rsquo;s status in order to set the
ingresses&rsquo; <code>status.loadBalancer.ingress</code>, which in turn is used by
ExternalDNS for setting the <code>A</code> records automatically. I still want to
be able to use ExternalDNS.</li>
</ol>
<p>Thus, my goal is expose Traefik on 80 and 443 and still use the <code>type: LoadBalancer</code> which, in turn, allows me to use ExternalDNS.</p>
<p>I could use the service&rsquo;s <code>externalIPs</code> but it isn&rsquo;t supported by Traefik
and I would have to write some controller that would get the node internal
IP and then set the <code>externalIPs</code> with these.</p>
<p>Instead, I opted for the <code>hostPort</code> solution. No restriction on 80 or 443.
But I still have to automate a lot. Fortunately,
<a href="https://github.com/kontena/akrobateo">akrobateo</a> does exactly what I need.</p>
<blockquote>
<p><code>hostPort</code> is a field you can set in a Pod. The hostPort is used by
kube-proxy to forward traffic coming to the node with the destination
<code>hostIP:hostPort</code> to the pod itself.</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="k">apiVersion</span><span class="p">:</span><span class="w"> </span>v1<span class="w">
</span><span class="w"></span><span class="k">kind</span><span class="p">:</span><span class="w"> </span>Pod<span class="w">
</span><span class="w"></span><span class="k">metadata</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">  </span><span class="k">name</span><span class="p">:</span><span class="w"> </span>akrobateo-lb-xmz8z<span class="w">
</span><span class="w"></span><span class="k">spec</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">  </span><span class="k">containers</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">  </span>- <span class="k">image</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;registry.pharos.sh/kontenapharos/akrobateo-lb:0.1.1&#34;</span><span class="w">
</span><span class="w">    </span><span class="k">ports</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">    </span>- <span class="k">containerPort</span><span class="p">:</span><span class="w"> </span><span class="m">443</span><span class="w">
</span><span class="w">      </span><span class="k">hostPort</span><span class="p">:</span><span class="w"> </span><span class="m">443</span><span class="w">                </span><span class="c"># ‚ö†Ô∏è</span><span class="w">
</span><span class="w">      </span><span class="k">name</span><span class="p">:</span><span class="w"> </span>https<span class="w">
</span><span class="w">      </span><span class="k">protocol</span><span class="p">:</span><span class="w"> </span>TCP<span class="w">
</span><span class="w"></span><span class="k">status</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">  </span><span class="k">hostIP</span><span class="p">:</span><span class="w"> </span><span class="m">172.31</span><span class="m">.4</span><span class="m">.153</span><span class="w">             </span><span class="c"># ‚ö†Ô∏è hostIP and hostPort go together</span><span class="w">
</span><span class="w">  </span><span class="k">podIP</span><span class="p">:</span><span class="w"> </span><span class="m">192.168</span><span class="m">.1</span><span class="m">.38</span><span class="w">
</span></code></pre></div><p>In this example pod, the pod runs on the node that has the hostIP
<code>172.31.4.153</code>. Any time traffic comes to the main network interface of
the node with the TCP packet destination <code>dst: 172.31.4.153:443</code> will be
forwarded (i.e., DNATed) to <code>dst: 192.168.1.38:443</code>.</p>
<p>Note that this pod was actually created using a DeamonSet.</p>
</blockquote>
<p>Akrobateo acts as an internal LoadBalancer service controller and replaces
the gce-ingress-controller that GKE applies to every GKE cluster. It is
inspired by K3S&rsquo;
<a href="https://github.com/rancher/k3s/blob/341a5553/pkg/servicelb/controller.go">servicelb</a>.</p>
<p>The akrobateo controller reads the LoadBalancer services and updates the
<code>status.loadBalancer.ingress</code> on these services with the node external IPs.
Whenever the external IPs change (since they are ephemeral), the controller
updates the service; Traefik does it job and finally ExternalDNS updates
the DNS records.</p>
<p>I might get some downtime with that, but for my use it&rsquo;s just fine.</p>
<h2 id="setting-up-akrobateo">Setting up Akrobateo</h2>
<p>That will install the akrobateo controller in the kube-system namespace:</p>
<div class="highlight"><pre class="chroma"><code class="language-sh" data-lang="sh">k apply -k https://github.com/kontena/akrobateo/deploy
</code></pre></div><p>Since we want TCP 80 and 443 traffic to be able to hit the nodes. Let&rsquo;s set
a new firewall rule:</p>
<div class="highlight"><pre class="chroma"><code class="language-sh" data-lang="sh">gcloud compute firewall-rules create akrobateo-fw-traefik --allow tcp:80,tcp:443 --source-ranges<span class="o">=</span>0.0.0.0/0
</code></pre></div><p>Also, make sure we don&rsquo;t have a L4 load balancer still running. The load
balancer won&rsquo;t get removed automatically.</p>
<div class="highlight"><pre class="chroma"><code class="language-sh" data-lang="sh">% gcloud compute forwarding-rules list
Listed <span class="m">0</span> items.
</code></pre></div><p>At this point, the LoadBalancer service should contain the IPs of the nodes:</p>
<div class="highlight"><pre class="chroma"><code class="language-sh" data-lang="sh">kubectl -n traefik get services traefik -oyaml
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="k">apiVersion</span><span class="p">:</span><span class="w"> </span>v1<span class="w">
</span><span class="w"></span><span class="k">kind</span><span class="p">:</span><span class="w"> </span>Service<span class="w">
</span><span class="w"></span><span class="k">metadata</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">  </span><span class="k">name</span><span class="p">:</span><span class="w"> </span>traefik<span class="w">
</span><span class="w">  </span><span class="k">namespace</span><span class="p">:</span><span class="w"> </span>traefik<span class="w">
</span><span class="w"></span><span class="k">spec</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">  </span><span class="k">clusterIP</span><span class="p">:</span><span class="w"> </span><span class="m">10.27</span><span class="m">.244</span><span class="m">.111</span><span class="w">
</span><span class="w">  </span><span class="k">externalTrafficPolicy</span><span class="p">:</span><span class="w"> </span>Cluster<span class="w">
</span><span class="w">  </span><span class="k">ports</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">  </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>http<span class="w">
</span><span class="w">    </span><span class="k">nodePort</span><span class="p">:</span><span class="w"> </span><span class="m">30371</span><span class="w">
</span><span class="w">    </span><span class="k">port</span><span class="p">:</span><span class="w"> </span><span class="m">80</span><span class="w">
</span><span class="w">    </span><span class="k">protocol</span><span class="p">:</span><span class="w"> </span>TCP<span class="w">
</span><span class="w">    </span><span class="k">targetPort</span><span class="p">:</span><span class="w"> </span>http<span class="w">
</span><span class="w">  </span>- <span class="k">name</span><span class="p">:</span><span class="w"> </span>https<span class="w">
</span><span class="w">    </span><span class="k">nodePort</span><span class="p">:</span><span class="w"> </span><span class="m">32748</span><span class="w">
</span><span class="w">    </span><span class="k">port</span><span class="p">:</span><span class="w"> </span><span class="m">443</span><span class="w">
</span><span class="w">    </span><span class="k">protocol</span><span class="p">:</span><span class="w"> </span>TCP<span class="w">
</span><span class="w">    </span><span class="k">targetPort</span><span class="p">:</span><span class="w"> </span>https<span class="w">
</span><span class="w">  </span><span class="k">type</span><span class="p">:</span><span class="w"> </span>LoadBalancer<span class="w">
</span><span class="w"></span><span class="k">status</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">  </span><span class="k">loadBalancer</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">    </span><span class="k">ingress</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="w">    </span>- <span class="k">ip</span><span class="p">:</span><span class="w"> </span><span class="m">35.211</span><span class="m">.248</span><span class="m">.124</span><span class="w">
</span><span class="w">    </span>- <span class="k">ip</span><span class="p">:</span><span class="w"> </span><span class="m">35.231</span><span class="m">.10</span><span class="m">.40</span><span class="w">
</span></code></pre></div><p>When displayed with <code>kubectl get</code>, we can see the two IPs from the
status.loadBalancer in the &ldquo;EXTERNAL-IP&rdquo; column:</p>
<div class="highlight"><pre class="chroma"><code class="language-sh" data-lang="sh">% kubectl -n traefik get services -owide
NAME                TYPE           CLUSTER-IP      EXTERNAL-IP                   PORT<span class="o">(</span>S<span class="o">)</span>
traefik             LoadBalancer   10.27.244.111   35.211.248.124,35.231.10.40   80:30371/TCP,443:32748/TCP
</code></pre></div><p>Let&rsquo;s check that these are the external IPs of the cluster nodes:</p>
<div class="highlight"><pre class="chroma"><code class="language-sh" data-lang="sh">% kubectl get nodes -owide
NAME                                                 INTERNAL-IP   EXTERNAL-IP
gke-august-period-234610-worker-0c5c84f5-rq25        10.142.0.61   35.231.10.40
gke-august-period-234610-worker-micro-cf12d79d-klh6  10.142.0.62   35.211.248.124
</code></pre></div><p>The <code>kube-system/akrobateo</code> controller will create a DeamonSet for every
LoadBalancer service it finds. The DeamonSet is created in the same
namespace as where the Service is:</p>
<div class="highlight"><pre class="chroma"><code class="language-sh" data-lang="sh">% kubectl get ds -A
NAMESPACE     NAME                       DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE
traefik       akrobateo-traefik          <span class="m">2</span>         <span class="m">2</span>         <span class="m">2</span>       <span class="m">2</span>            <span class="m">2</span>
</code></pre></div><p>This DeamonSet runs one pod per node, each pod being responsible for
proxying everything coming to the host&rsquo;s 80 and 443 ports to Traefik (see
description of the network flow below).</p>
<p>Let&rsquo;s make sure ExternalDNS uses the correct IPs:</p>
<div class="highlight"><pre class="chroma"><code class="language-sh" data-lang="sh">k -n external-dns logs -l app.kubernetes.io/name<span class="o">=</span>external-dns -f
<span class="nv">time</span><span class="o">=</span><span class="s2">&#34;2020-01-18T17:26:31Z&#34;</span> <span class="nv">level</span><span class="o">=</span>debug <span class="nv">msg</span><span class="o">=</span><span class="s2">&#34;Endpoints generated from ingress: traefik/traefik-dashboard: [traefik.kube.maelvls.dev 0 IN A  35.211.248.124 [] traefik.kube.maelvls.dev 0 IN A  35.211.248.124 []]&#34;</span>
</code></pre></div><p>There still is a slight issue here: we would expect ExternalDNS to set a
<code>A</code> record with both IPs (35.211.248.124 and 35.231.10.40). But for some
reason, it doesn&rsquo;t. As we have seen previously, the Akrobateo controller
has successfully updated the traefik/traefik service (type LoadBalancer).
And since Traefik is the ingress controller responsible for setting the
<code>status.loadBalancer.ingress</code> on ingresses, Traefik is probably the culprit
and might simply pick the first element.</p>
<h2 id="pros-and-cons">Pros and cons</h2>
<ul>
<li>
<p><strong>Isn&rsquo;t <code>hostPort</code> a bad practice?</strong> From the <a href="https://kubernetes.io/docs/concepts/configuration/overview/#services">Kubernetes
documentation</a>:</p>
<blockquote>
<p>Don&rsquo;t specify a <code>hostPort</code> for a Pod unless it is absolutely necessary.
When you bind a Pod to a <code>hostPort</code>, it limits the number of places the
Pod can be scheduled, because each &lt;<code>hostIP</code>, <code>hostPort</code>, <code>protocol</code>&gt;
combination must be unique.</p>
<p>[When using <code>hostPort</code>,] if you don&rsquo;t specify the <code>hostIP</code> and
<code>protocol</code> explicitly, Kubernetes will use <code>0.0.0.0</code> as the default
<code>hostIP</code> and <code>TCP</code> as the default <code>protocol</code>.</p>
<p>If you explicitly need to expose a Pod‚Äôs port on the node, consider
using a
<a href="https://kubernetes.io/docs/concepts/services-networking/service/#nodeport">NodePort</a>
Service before resorting to <code>hostPort</code>.</p>
</blockquote>
<p>I do not fuly grasp what are the implications of using a hostPort. I
guess it &ldquo;litters&rdquo; the iptables on the node? I&rsquo;m not sure.</p>
</li>
<li>
<p><strong>What if I have many more nodes, can it scale?</strong> I guess it won&rsquo;t. Maybe
one idea would be to leader-elect two or three nodes and put only these
two or three IPs in <code>status.loadbalancer.ingress[]</code>. If one of the nodes
fails, the DNS will be updated; the client will be able to failover using
the two or three IPs from the DNS record.</p>
</li>
<li>
<p><strong>Reliability?</strong> If the nodes that are advertised in the <code>A</code> DNS records
go down, no more ingress traffic possible.</p>
</li>
<li>
<p><strong>What if the node&rsquo;s external-ip changes?</strong> Since these IPs are
ephemeral, the controller will pick up this change and change the
<code>status.loadBalancer.ingress</code> field of my <code>type: LoadBalancer</code> service.</p>
</li>
</ul>
<h2 id="how-does-it-work">How does it work?</h2>
<p>Since I created a firewall rule for 80 and 443, GCE forwards the traffic
from 35.211.248.124 (the node&rsquo;s external-ip) to 10.142.0.62 (the node&rsquo;s
internal-ip). And since we use <code>hostPort</code>, kubelet creates some iptable
rules that redirect traffic to the pod running on that node:</p>
<div class="highlight"><pre class="chroma"><code class="language-sh" data-lang="sh">% gcloud compute ssh gke-august-period-234610-worker-micro-cf12d79d-klh6 --command<span class="o">=</span><span class="s1">&#39;sudo iptables-save&#39;</span> <span class="p">|</span> egrep <span class="s2">&#34;(HOSTPORT|HP)&#34;</span>
-A PREROUTING -m comment --comment <span class="s2">&#34;kube hostport portals&#34;</span> -m addrtype --dst-type LOCAL -j KUBE-HOSTPORTS
-A OUTPUT -m comment --comment <span class="s2">&#34;kube hostport portals&#34;</span> -m addrtype --dst-type LOCAL -j KUBE-HOSTPORTS
-A PREROUTING -m comment --comment <span class="s2">&#34;kube hostport portals&#34;</span> -m addrtype --dst-type LOCAL -j KUBE-HOSTPORTS
    <span class="c1"># If the packet destination is local (localhost or 127.*), continue with KUBE-HOSTPORTS.</span>
-A KUBE-HOSTPORTS -p tcp -m comment --comment <span class="s2">&#34;akrobateo-traefik-4jh5k_traefik hostport 443&#34;</span> -m tcp --dport <span class="m">443</span> -j KUBE-HP-A7HWACIJNU4N3R5W
    <span class="c1"># If it is a TCP packet and the destication port is 443, continue with KUBE-HP-A7HWACIJNU4N3R5W</span>
-A KUBE-HP-A7HWACIJNU4N3R5W -s 10.24.4.2/32 -m comment --comment <span class="s2">&#34;akrobateo-traefik-4jh5k_traefik hostport 443&#34;</span> -j KUBE-MARK-MASQ
    <span class="c1"># If the source IP of the packet is the akrobateo proxy pod, this packet is egressing: continue with KUBE-MARK-MASQ (masquarade)</span>
-A KUBE-HP-A7HWACIJNU4N3R5W -p tcp -m comment --comment <span class="s2">&#34;akrobateo-traefik-4jh5k_traefik hostport 443&#34;</span> -m tcp -j DNAT --to-destination 10.24.4.2:443
    <span class="c1"># If the source wasnt this pod, then we assume it is some ingress. We replace the destination with the pods ClusterIP.</span>
</code></pre></div><p>Then, when it is in the pod, the pod&rsquo;s iptables will kick in and redirect.
Nothing is actually running in the pod, except for the namespaced network
stack. These pods have:</p>
<ul>
<li>
<p>an init container that runs <code>sysctl -w net.ipv4.ip_forward=1</code> (see
<a href="https://kubernetes.io/docs/concepts/cluster-administration/networking/#google-compute-engine-gce">k8s-networking-gce</a>) in privileged mode, which enables forwarding
inside the pod (does not affect the host).</p>
</li>
<li>
<p>two containers set iptables and then <code>pause</code>. In order to alter its
namespaced TCP stack, we give the containers the NET_ADMIN capability
(these rules only affect the pod, not the host).</p>
<div class="highlight"><pre class="chroma"><code class="language-sh" data-lang="sh">sudo iptables -t nat -I PREROUTING ! -s 10.27.244.111/32 -p TCP --dport <span class="m">80</span> -j DNAT --to 10.27.244.111:80
sudo iptables -t nat -I POSTROUTING -d 10.27.244.111/32 -p TCP -j MASQUERADE
sudo iptables -t nat -I PREROUTING ! -s 10.27.244.111/32 -p TCP --dport <span class="m">443</span> -j DNAT --to 10.27.244.111:443
sudo iptables -t nat -I POSTROUTING -d 10.27.244.111/32 -p TCP -j MASQUERADE
</code></pre></div></li>
</ul>
<p>Here is a diagram that shows the whole picture:</p>
<p><img src="packet-routing-with-akrobateo.png" alt="Packet routing using Akrobateo, Traefik and iptables"></p>
<h2 id="akrobateo-vs-k3ss-servicelb-controller">Akrobateo vs. K3s&rsquo;s servicelb controller</h2>
<p><a href="https://github.com/rancher/k3s">K3s</a> has this same idea of &ldquo;service type
loadbalancer controller&rdquo; embedded to K3s itself. The controller, called
&ldquo;servicelb&rdquo;
(<a href="https://github.com/rancher/k3s/blob/master/pkg/servicelb/controller.go">servicelb/controller.go</a>)
runs as a Deployment and a DeamonSet running
<a href="https://github.com/rancher/klipper-lb">klipper-lb</a> that uses pod&rsquo;s
<code>hostPort</code> and the pod&rsquo;s iptables to forward traffic to the cluster-ip of
the service. I don&rsquo;t know yet what are the differences between Akrobateo
and K3s&rsquo; servicelb. Note that Akrobateo itself is based on servicelb.</p>
<h2 id="recap">Recap</h2>
<ul>
<li>Akrobateo is a controller that watches Services of <code>type: LoadBalancer</code>;</li>
<li>When it finds one, creates a deamonset of empty pods.</li>
<li>The task of these empty pods is to set one iptable rule that redirects
traffic to the ClusterIP of the <code>type: LoadBalancer</code> service.</li>
<li>Akrobateo also sets the Service&rsquo;s status with the loadBalancer IP.</li>
<li>Benefit: since the loadBalancer IP is properly set, ExternalDNS works!</li>
</ul>
<!--
Want to drop a comment? Here is a Twitter thread:

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">GKE is great and everything but the default ‚Ç¨17 load balancer is just too much for my &quot;playground&quot; cluster.<br><br>Here is how I avoid it by using a custom loadbalancer controller <br> (kontena/akrobateo) with ExternalDNS and Traefik:<a href="https://t.co/8TjrrUi4Sg">https://t.co/8TjrrUi4Sg</a></p>&mdash; Ma√´l Valais (@maelvls) <a href="https://twitter.com/maelvls/status/1219193625478881285?ref_src=twsrc%5Etfw">January 20, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

-->
<!-- 
## Metallb vs. K3s' servicelb vs. akrobateo

- metallb = vrrp + arp (l2), see "[MetalLB Layer 2 concepts](https://metallb.universe.tf/concepts/layer2/)"

ARP = 
NDP = 

MetalLB implements something close to VRRP.

-->
<p><strong>Update 22 April 2020:</strong></p>
<ul>
<li>Akrobateo <a href="https://twitter.com/i/status/1219193625478881285">is EOL</a>
since January 2020 üò¢ I added a note about that.</li>
<li>Better introduction.</li>
<li>Explain what I mean by <code>hostPort</code>.</li>
<li>In &ldquo;Isn&rsquo;t <code>hostPort</code> a bad practice?&quot;, I replaced &ldquo;I don&rsquo;t know&rdquo; with a
<a href="https://kubernetes.io/docs/concepts/configuration/overview/#services">link</a>
to the Kubernetes documentation that mention why I should avoid hostPort.</li>
<li>In &ldquo;What if I have many more nodes, can it scale?&quot;, I replaced &ldquo;I don&rsquo;t
know&rdquo; with a proposition of solution.</li>
<li>Detail how K3s&rsquo; servicelb is similar to Akrobateo.</li>
</ul>

</div>
<a href="https://github.com/maelvls/maelvls.github.io/edit/source/content/2020/avoid-gke-lb-using-hostport/index.md">üìù Edit this page and propose a change!</a>
<div class="tags">










<div style="float: right;">
<p>Tags:













































































<a href="/tags/kubernetes/"> kubernetes </a>





















<a href="/tags/networking/"> networking </a>



























</div>
<div class="clearit"></div>





</div>

<script
  src="https://utteranc.es/client.js"
  repo="maelvls/maelvls.github.io"
  issue-term="pathname"
  label="üí¨"
  theme="github-light"
  crossorigin="anonymous"
  async
></script>
</div>

</main><footer>



<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-88710120-3', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

</footer>
</body>
</html>
